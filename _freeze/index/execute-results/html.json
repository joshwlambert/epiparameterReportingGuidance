{
  "hash": "1dd219d08cdad1527013dfd7835650d1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Recommendations for reporting epidemiological parameters\nauthor:\n  - name: Joshua W. Lambert\n    orcid: 0000-0001-5218-3046\n    corresponding: true\n    email: joshua.lambert@lshtm.ac.uk\n    affiliations:\n      - London School of Hygiene and Tropical Medicine\n  - name: Carmen Tamayo\n    orcid: 0000-0003-4184-2864\n    corresponding: false\n    email: carmen.tamayo-cuartero@lshtm.ac.uk\n    affiliations:\n      - London School of Hygiene and Tropical Medicine\n  - name: Sangeeta Bhatia\n    orcid: 0000-0001-6525-101X\n    corresponding: false\n    email: s.bhatia@imperial.ac.uk\n    affiliations:\n      - Imperial College London\n      - UK Health Security Agency\n  - name: Ruth McCabe\n    orcid: 0000-0002-6368-9103\n    corresponding: false\n    email: ruth.mccabe17@imperial.ac.uk\n    affiliations:\n      - Imperial College London\n  - name: Gina Cuomo-Dannenburg\n    orcid: 0000-0001-6821-0352\n    corresponding: false\n    email: g.cuomo-dannenburg18@imperial.ac.uk\n    affiliations:\n      - Imperial College London\n  - name: Adam Kucharski\n    orcid: 0000-0001-8814-9421\n    corresponding: false\n    email: adam.kucharski@lshtm.ac.uk\n    affiliations:\n      - London School of Hygiene and Tropical Medicine\n  - name: Anne Cori\n    orcid: 0000-0002-8443-9162\n    corresponding: false\n    email: a.cori@imperial.ac.uk\n    affiliations:\n      - Imperial College London\nkeywords: \n  - epidemiological parameters\n  - reporting guidelines\ndate: last-modified\nbibliography: references.bib\n---\n\n\n\n\n\nEpidemiological parameters are a necessity in understanding the spread of infectious disease; from the rate of transmission, to severity, to serology, these parameters underline our ability to quantify and respond to disease outbreaks. The estimation of epidemiological parameters has a long history in epidemiology and the models and methods applied have become more complex; and with this complexity comes the numerous ways parameters can be reported in the literature.  Here we provide guidance on how to clearly communicate estimated epidemiological parameters, to maximise their secondary use and minimise possible human errors that come with extracting parameters from the literature and applying them in their own epidemiological analysis. Our aim is for future work that reports epidemiological parameters to be consistent, reproducible and comparable.\n\n\n\n## Introduction\n\nEpidemiological parameters are quantities that characterise the spread of infectious diseases, their epidemiological outcomes and temporal information on dynamics of disease progression and transmission [@coriInferenceEpidemicDynamics2024]. They are critical to understand epidemic and pandemic dynamics and respond accordingly [@polonskyOutbreakAnalyticsDeveloping2019]. Most epidemiological parameters take the form of distributions because there is inherent variability in the epidemiological characteristics being measured. An illustration is the delay from infection to symptom onset. The variability of individuals in immune response and variability of the infectious agent in pathology are two ways, among many others, that lead to some individuals having shorter time delay between infection and onset of symptoms. Due to most epidemiological parameters being described by distributional forms they are estimated by fitting distributions to epidemiological data on cases or contacts.\n\nIt has become general practice that when epidemiological parameters are required, either for analyses of epidemiological case data or to make policy decisions like quarantine duration, that the literature is searched to find a suitable peer-reviewed publication reporting the parameter needed. However, this process has several limitations. The time requirement to search through papers to find the highest quality epidemiological parameter means that in time-limited scenarios, for example early in an outbreak when the situation is evolving rapidly and new data is continually gathered, a suboptimal parameter set may be extracted and used. This has lead to previous _ad hoc_ reviews of epidemiological parameters for specific pathogens (e.g. Ebola [@vankerkhoveReviewEpidemiologicalParameters2015a]). The choice of parameter is also likely to be somewhat subjective without a clear quality assurance framework to evaluate and compare different parameter estimates. The manual extraction of copying and pasting parameters out of the literature comes with the risk of discrepancies entering the calculations.\n\nEpidemiological parameters have been reported for many diseases and the data used to infer parameter estimates and the methods of inference vary.\n\nEfforts to compile a centralised database of epidemiological parameters have highlighted the variability and ambiguity in parameter reporting which can lead to uncertainty around what is being reported and how these epidemiological parameters can be applied in other epidemiological analyses [@cuomo-dannenburgMarburgVirusDisease2024; @doohanLassaFeverOutbreaks2024; @nashEbolaVirusDisease2024].\n\nThis paper was motivated by several research groups independently attempting to compile a comprehensive library of epidemiological parameters which could serve as a public resource to easily search, filter and extract parameters. These groups gathered for a workshop convened by the World Health Organisation (WHO) Collaboratory in Spring 2024, in which a Global Repository of Epidemiological Parameters (GREP) was discussed, as well as ideas for guidance on reporting epidemiological parameters. The guidelines and examples of incorrect reporting and use were subsequently further developed and resulted in this paper.\n\nOur focus is on guidance for reporting epidemiological parameters from a variety of study types and estimation methodologies. We do not cover or advice on best practises for parameter estimation methods. There are several papers that address avoiding biases and pitfalls [@kingAvoidableErrorsModelling2015; brittonEstimationEmergingEpidemics2019a]. Specificall for guidance on methodologies when inferring delay distributions see @parkEstimatingEpidemiologicalDelay2024 and @charnigaBestPracticesEstimating2024, and when inferring the reproduction number see @gosticPracticalConsiderationsMeasuring2020a and abbottEstimatingTimevaryingReproduction2020. We focus on the reporting of epidemiological parameters post-inference and the benefits of reporting standardisation on the reuse of parameters by those involved in epidemic or humanitarian response.\n\nWe classify bad parameter reporting into two groups: 1) _information loss_ and 2) _ambiguous reporting_. Information loss is defined as the presentation or sharing of less than the entirety of the parameter estimates, metadata and contextual information. For example, if a method to infer a case fatality rate outputs the uncertainty of the risk but this is not reported either in the text and the method cannot be reproduced then this information is lost when others extract the parameters, i.e. only a subset of the full inference is shared. Ambiguous reporting can be either the ambiguous reporting of metrics, such as a $X \\pm Y$ where $Y$ could be the standard deviation or standard error, or $X (Y_1 - Y_2)$ where the bounds $Y_1$ and $Y_2$ could be a confidence interval or credible interval when the inference framework is not reported. In both cases the secondary use of the parameters either is forced to make an assumption on what is reported, or does not utilise the information resulting in information loss.\n\nHere we focus on the bias caused by badly reported epidemiological parameters on simple epidemic methods, sometimes referred to as outbreak analytics [sensu @polonskyOutbreakAnalyticsDeveloping2019], to showcase the erroneous conclusions that can arise when using parameter estimates from the literature. The biases produce here will likely extrapolate to more complex epidemiologilogical modelling. Reporting guidelines can ensure standardised reporting becomes more commonplace, which can make it easier to review, summarise and aggregate epidemiological parameters. We hope that this paper, alongside other works on reporting best practises in epidemiology [@pollettRecommendedReportingItems2021; @charnigaBestPracticesEstimating2024] enhance the interoperability of research outputs and inputs.\n\n## Guidance\n\n### Parameter inference reporting\n\n#### Parameterisation of distributions\n\nMany distributions have standard parameterisations. In other words, they have one, two or in some cases three parameters that are denoted by a name and often have a greek letter for shorthand. An example of this is the Gamma distribution which has the parameterisation shape ($\\alpha$) and rate ($\\beta$). However, there are often alternative parameterisations, for the Gamma distribution this is shape ($k$) and scale ($\\theta$). If left unspecified, the reported parameters may correspond to different parameters depending on interpretation. Another example of ambiguous reporting of distribution estimates is when the parameters and summary statistics have similar names. This is the case for the lognormal distribution, whose common parameterisation is meanlog ($\\mu$) and sdlog ($\\sigma$) and common summary statistics reported for a distribution are mean and standard deviation (sd), this is further confused as both use the same greek letters. Therefore, it is possible to mistake the reporting of one set of these for the other. Both types of misinterpretation outlined here can result in substantial differences in the distributions (Figure 1).\n\n::: {.callout-note title=\"_Guidance_\"}\n* Provide the formula for the Probability Density Function (PDF), or Probability Mass Function (PMF) if discrete, in the text or supplementary material.\n* Clearly report which distribution parameterisation was used to estimate parameters and provide parameter names in the text. \n* Share code used to estimate parameter(s) for others to reproduce and audit methods.\n:::\n\n\n\n\n\n\n\n{{< embed use_cases/dist_params.qmd#fig-dist-params >}}\n\n\n\n\n\n\n\n\n\n\n#### Parameter estimates vs summary statistics\n\nInstead of reporting the parameter estimates for a parametric distribution, summary statistics may be provided. In some instances a set of summary statistics can be analytically converted into distribution parameters (the specific summary statistics that can be converted into parameters varies by distribution). In those cases where analytical conversion can be done there is no loss in parameter estimate precision, i.e. summary statistics are sufficient statistics. Commonly reported sufficient statistics are the mean and standard deviation or variance of a distribution. However, it can also be the case that summary statistics that cannot be analytically converted to distribution parameters are reported, for example the mean or median and the 95th percentiles of the distribution. In these cases, distribution parameters require a second estimation using a numerical conversion. Numerical conversion can introduce more uncertainty and potentially return erroneous estimates. Below we show an example of the bias and variance of distribution parameters when numerically converted from summary statistics… (see {epiparameter} R package article for full exploration of bias in numerical conversion).\n\nEpidemiological parameters can be dimensionless quantities, for example R0 or secondary attack rate, while others have units. It is especially critical for the accurate reuse of with dimensions parameters that the units are reported. For parameters with a temporal dimension, such as delay distributions, the unit of time ensures that distributions fitted to data on days or weeks can be clearly understood. Another example is viral load data that can be reported as Ct or log10 RNA copies/ml. Many epidemiological parameters will have conventional units, for example incubation period and serial interval in days, or population density in individuals/km, but if readers have to assume units then misinterpretation can have consequences for others that apply the findings in their own work.\n\n_Guidance_:\n\n* Report the estimated distribution parameters first and foremost before optionally reporting summary statistics. This will avoid any secondary estimation step which can introduce unwanted and unnecessary bias. \n* If a parameter has a unit, report this with the estimates, ensuring it matches the data of input of the model.\n\n::: {.callout-tip}\n## Use case: Severity\n\n**Use case: Ambiguous reporting of onset-to-death delay distribution and erroneous CFR estimates**\n\nIn a scenario in which the case fatality risk (CFR) needs to be calculated for an ongoing, growing disease outbreak an onset-to-death delay distribution is required to calculate an unbiased CFR estimate, due to some individuals being infected but theiry outcome (i.e recovery or death) is unknown @nishiuraEarlyEpidemiologicalAssessment2009.\n\nA line list of the current outbreak is available, but no estiates of the onset-to-death delay are available for this outbreak and there is not enough case data to reliably estimate it from the line list. Therefore a previously inferred onset-to-death distribution is searched and extracted from the literature for the same pathogen from a past outbreak.\n\nThe paper reporting the onset-to-death states:\n\n> \"... the average duration between the time when symptoms first appeared and death of the patients was estimated. The mean onset-to-death delay was of 14.5 days, with a standard deviation of 6.7.\"\n\nThe ambiguous reporting of the esimates means the onset-to-death delay can be (mis)interpreted in several ways. The paper is reporting the summary statistics mean and standard deviation for a lognormal distribution they fitted to the data. The estimates could be misinterpreted as meanlog and sdlog do the lognormal distribution, or could be misinterpreted as the summary statistics of the raw data (i.e. sample statistics). The CFR calculation for an unbiased estimate requires a parametric probability density/mass function. Therefore, given the ambiguity we demonstrate the correct interpretation and three misinterpretations of the reported onset-to-death and show how the CFR varies as a result. We use the {simulist} and {cfr} R packages to simulate line list data and calculate the CFR, respectively @lambertSimulistSimulateDisease2024 and @gupteCfrEstimateDisease2024.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Use case for reporting guidance paper #2- Mean of the sample reported\n# ambiguously so it's confused with the mean of the lognormal distribution\nlibrary(simulist)\nlibrary(epiparameter)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(incidence2)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: grates\n\nAttaching package: 'grates'\n\nThe following objects are masked from 'package:lubridate':\n\n    epiweek, isoweek, year\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(cfr)\nlibrary(tidyr)\nlibrary(dplyr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Step 1: Simulating data for the use case with o-d lognormal and CFR of 30%\ncontact_distribution <- epiparameter(\n  disease = \"COVID-19\",\n  epi_dist = \"contact distribution\",\n  prob_distribution = \"pois\",\n  prob_distribution_params = c(mean = 3)\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCitation cannot be created as author, year, journal or title is missing\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nip_COVID <- epiparameter(\n  disease = \"COVID-19\",\n  epi_dist = \"infectious period\",\n  prob_distribution = \"gamma\",\n  prob_distribution_params = c(shape = 3, scale = 3)\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCitation cannot be created as author, year, journal or title is missing\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\no_d_COVID <- epiparameter_db(\n  disease = \"covid-19\",\n  epi_dist = \"onset to death\",\n  single_epiparameter = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing Linton N, Kobayashi T, Yang Y, Hayashi K, Akhmetzhanov A, Jung S, Yuan\nB, Kinoshita R, Nishiura H (2020). \"Incubation Period and Other\nEpidemiological Characteristics of 2019 Novel Coronavirus Infections\nwith Right Truncation: A Statistical Analysis of Publicly Available\nCase Data.\" _Journal of Clinical Medicine_. doi:10.3390/jcm9020538\n<https://doi.org/10.3390/jcm9020538>.. \nTo retrieve the citation use the 'get_citation' function\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nset.seed(123)\nlinelist_covid <- sim_linelist(\n  contact_distribution = contact_distribution, \n  infectious_period = ip_COVID,\n  prob_infect = 0.7,\n  onset_to_hosp = NULL,\n  hosp_risk = NULL,\n  non_hosp_death_risk = 0.3,\n  onset_to_death = o_d_COVID,\n  outbreak_size = c(1000, 2000)\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Number of cases exceeds maximum outbreak size. \nReturning data early with 2272 cases and 3246 total contacts (including cases).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# STEP 2: Aggregation\nlinelist_covid <- linelist_covid %>%\n  tidyr::pivot_wider(\n    names_from = outcome,\n    values_from = date_outcome\n  ) %>%\n  dplyr::rename(\n    date_death = died,\n    date_recovery = recovered\n  )\n\nincidence_COVID <- incidence2::incidence(\n  linelist_covid, \n  date_index = c(\"date_onset\", \"date_death\"), \n  interval = 1L\n)\n\nincidence_COVID$date_index <- as.Date(incidence_COVID$date_index)\ncovid_inc_cfr <- cfr::prepare_data(\n  incidence_COVID, \n  cases_variable = \"date_onset\", \n  deaths_variable = \"date_death\"\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nNAs in cases and deaths are being replaced with 0s: Set `fill_NA = FALSE` to prevent this.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nggplot2::ggplot(\n  data = covid_inc_cfr, \n  mapping = ggplot2::aes(x = date)\n) + \n  ggplot2::geom_point(\n    mapping = ggplot2::aes(y = cases), \n    colour = \"blue\"\n  ) +\n  ggplot2::geom_point(\n    mapping = ggplot2::aes(y = deaths), \n    colour = \"red\") + \n  ggplot2::theme_bw() + \n  ggplot2::scale_x_date(date_breaks = \"7 days\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# STEP 3: Truncating data\n# Real-time point at 2023-01-09\n\nreal_time <- \"2023-01-27\"\nincidence_rt_covid <- covid_inc_cfr[covid_inc_cfr$date <= real_time,]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# STEP 4: Converting parameters\ntrue_dist_params <- get_parameters(o_d_COVID)\ntrue_dist_summary_stats <- convert_params_to_summary_stats(\"lnorm\", meanlog = true_dist_params[[\"meanlog\"]], sdlog = true_dist_params[[\"sdlog\"]])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# STEP 5: Problem statement\n\n# We want to estimate the delay-adjusted CFR on our own outbreak data, and for this\n# we look at the available literature where we find a publication that reports the delay\n# from disease onset to death as follows:\n# \"... the average duration between the time when symptoms first appeared and\n# death of the patients was estimated. The mean onset-death delay was of 14.5 days,\n# with a standard deviation of 6.7\"\n\n\n# 14.5 and 6.7 are really distribution summary stats\n\n# TRUE CFR\n\ntrue_cfr <- cfr::cfr_static(\n  incidence_rt_covid, \n  delay_density = function(x) {\n    dlnorm(\n      x, \n      meanlog = true_dist_params[[\"meanlog\"]], \n      sdlog = true_dist_params[[\"sdlog\"]]\n    )\n  }\n)\n\n# a) We think they are meanlog and sdlog\ncrf_assumed_params <- cfr::cfr_static(\n  incidence_rt_covid, \n  delay_density = function(x) {\n    dlnorm(\n      x, \n      meanlog = true_dist_summary_stats[[\"mean\"]], \n      sdlog = true_dist_summary_stats[[\"sd\"]]\n    )\n  }\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nTotal deaths = 22 and expected outcomes = 14 so setting expected outcomes = NA. If we were to assume\n        total deaths = expected outcomes, it would produce an estimate of 1.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# b) We think they are sample statistics\n# b.1) Lognormal to randomly generate sample and lognormal fitted distribution\nlnorm_sample <- rlnorm(\n  n = 500, \n  meanlog = true_dist_params[[\"meanlog\"]], \n  sdlog = true_dist_params[[\"sdlog\"]]\n)\n\nlnorm_fit <- fitdistrplus::fitdist(data = lnorm_sample, distr = \"lnorm\")\n\ncfr_sample_lnorm <- cfr::cfr_static(\n  incidence_rt_covid, \n  delay_density = function(x) {\n    dlnorm(\n      x, \n      meanlog = lnorm_fit$estimate[[\"meanlog\"]], \n      sdlog = lnorm_fit$estimate[[\"sdlog\"]]\n    )\n  }\n)\n\n# b.2) Gamma and gamma\ngamma_parameters <- convert_summary_stats_to_params(\n  \"gamma\",\n  mean = true_dist_summary_stats[[\"mean\"]], \n  sd = true_dist_summary_stats[[\"sd\"]]\n)\n\ngamma_sample <- rgamma(\n  n = 500, \n  shape = gamma_parameters$shape, \n  scale = gamma_parameters$scale\n)\n\ngamma_fit <- fitdistrplus::fitdist(data = gamma_sample, distr = \"gamma\")\n\ncfr_sample_gamma <- cfr::cfr_static(\n  incidence_rt_covid, \n  delay_density = function(x) {\n    dgamma(\n      x, \n      shape = gamma_fit$estimate[[\"shape\"]], \n      rate = gamma_fit$estimate[[\"rate\"]]\n    )\n  }\n)\n```\n:::\n\n\n\n\n\n\nThe correct interpretation can analytically convert the mean and standard deviation to the lognormal distribution parameters ($\\mu$ = 2.86, $\\sigma$ = 0.53) and parameterise the onset-to-death, resulting in a CFR of 0.3042, or 30\\.42%. Misinterpreting the estimates to be the lognormal parameters results in an overestimated CFR of NA. Assuming that the reported estimates are sample summary statistics, the distribution can be assumed, here we test the assumption that it is a lognormal (correct assumption) and a gamma distribution (incorrect assumption). The assumed parametric distribution form can be used to simulate a sample and the same distribution can be fit to that sample to estimate the parameters. In the case of assuming a lognormal distribution the CFR is estimated as 0.2681, whereas assuming a gamma distribution results in a CFR of 0.2426. The estimated CFR is biased in both cases but more so when the distribution is assumed incorrectly. \n\n\n:::\n\n#### Parameter uncertainty vs sample variability\n\nThe reporting of distributions is to encapsulate the variability of epidemiological delays, transmission, severity and others. However, there is also uncertainty around the parameters estimated. If it is not clearly stated that a distribution was fit to the data, it can be unclear whether the uncertainty around the mean corresponds to variation in the epidemiological case data, i.e. differences between individuals resulting in a distribution, or to the confidence or credible interval around the estimated mean. \n\n#### Reporting inference method\n\nThe inference method used to infer epidemiological parameters and the uncertainty that is coupled with those estimates is also important to report precisely for it to be used in downstream analyses. One common distinction that can be made between inference method is whether it uses Maximum likelihood estimation (MLE) or Bayesian estimation. The resulting uncertainty of parameters, confidence intervals (CI) for MLE and credible intervals (CrI) for Bayesian fitting, cannot be interpreted or applied interchangeably [@moreyFallacyPlacingConfidence2016]. Therefore if wanting to propagate uncertainty in parameter estimates, incorrectly treating CI as CrI or vice versa will lead to bias.\n\nReporting on Bayesian fitting also has several summary statistics to describe the central tendency of the inferred posterior sample, for example, mean, median, mode. It is beneficial for the specific central tendency statistic used to be explicitly stated.\n\n_Guidance_:\n\n* Report distribution parameters with uncertainty if available. This can be reporting the confidence interval (CI) or credible interval (CrI) making it clear \n* When using Bayesian inference, specifying methods used for posterior distribution and making posterior sample openly available via data sharing platform, e.g., Zenodo, Data Dryad.\n\nThe types of distributions commonly fit to estimate delay distributions, such as serial interval, onset-to-event and incubation period, are Gamma, lognormal and Weibull. These are used as they are strictly positive (sometimes offsets or other distributions are used to account for negative serial intervals (Prete Jr. et al., 2021)) and are right-skewed, meaning that most of the distribution mass (i.e. area under the curve) is the left of the mean (Figure 1). It is best practice to fit multiple distributions to the data and compare models using likelihoods, information criteria or likelihood ratio tests. By reporting these comparisons with each set of estimated parameters it allows others to use the distribution they choose while also being aware of the goodness-of-fit if choosing the non-best-fitting distribution. \n\n_Guidance_: \n\n* If multiple distributions are fit to the raw case data, report the goodness-of-fit (e.g. maximum likelihood, Akaike Information Criterion) and the parameter estimates of each distribution either in the main text or in the supplementary material. \n\n### Contextual information and metadata\n\nSince pathogen transmission and spread is known to be affected by socioeconomic, demographic, and climatic factors, reporting relevant contextual information alongside parameter estimates is crucial to understand the circumstances in which these estimates were obtained. Doing so will allow external readers to make informed decisions about the generalisability of the reported parameters and usability in their own analyses. \n\nAn important contextual element is detailed information about the sample population from which parameters were estimated, including factors such as the geographic location, age distribution, and comorbidities. This is particularly relevant in those studies where only a specific subset of the population was sampled, such as health-care workers, pregnant individuals, or immunocompromised patients. \n\nOther relevant details of the study, such as the type of design and sampling strategy, should not be overlooked, when reporting epidemiological parameters, as these provide relevant contextual information to assess the representativeness of the data and validity of the statistical methods applied. For instance, methods for estimating parameters like the serial interval require considering data collection methods, as different adjustments for biases are needed depending on whether data on transmission pairs was conducted prospectively or retrospectively (see section 1.5). The specific case definition used to estimate parameters should also be reported, where possible, given the range of clinical signs that many diseases exhibit at different stages of infection, which can have an impact on the estimation of parameters like the incubation period or delays from onset to outcome.\n\n::: {.callout-tip}\n## Use case: Seroprevalence\n\n**Example use case: the importance of clear reporting of seroprevalence estimates**\n\n\n\n\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\nlibrary(matrixStats)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'matrixStats'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    count\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(binom)\noptions(scipen=999)\n```\n:::\n\n::: {.cell .hidden}\n\n```{.r .cell-code}\n# essentially we have a scenario in which the neutralisation tests are not reported with the correct denominator and it implies a higher seroprevalence than it actually is, which in turn could suggest a smaller susceptible population \n\n# set up some numbers\ntotal_tests <- 5000\npositive_elisa <- 250\npositive_neutralisation <- 50\n\n## could then also talk about if this was just HCWs but that seems patronising?\n```\n:::\n\n\n\n\n\nEstimates of seroprevalence provide critical insights into the level of susceptibility within a population, in turn informing the implementation of control measures, including vaccinations (e.g. through the critical fraction requiring vaccination to control spread). \\\nA novel coronavirus has been identified and is spreading throughout the population. A rapid seroprevalence study is undertaken to understand levels of immunity of the population. Initially, 5,000 tests are carried out via enzyme-linked immunoabsorbsent assay (ELISA), of which 250 are positive. This corresponds to a seroprevalence estimate of 5% (95% exact binomial confidence intervals 4.4% - 5.6%). \\\nHowever, it is known that ELISA assays can be prone to cross-reactivity with other coronaviruses, which are also in circulation in this population. Therefore, it is decided to undertake neutralisation tests, which are typically more sensitive, to provide further confidence in the level of population-immunity. Due to a limited budget, only 500 tests can be re-tested with a neutralisation assay, and so all of the 250 positive tests and 250 of the 4,750 negatives are selected randomly for further testing.\\\nOf the 500 samples sent for further testing, only 50 return as positive. For the neutralisation tests, in respect of the ELISA tests, this corresponds to a seroprevalence estimate of 10% (95% exact binomial confidence intervals 7.5% - 13%), which is notably higher than the seroprevalence obtained under ELISA only. \\\nHowever, discounting the results of the 4,500 tests incorrectly inflates estimated seroprevalence, implying a higher level of immunity in the population than that which is indicated by this study as a whole. Looking at the positive neutralisation tests out of the total tests (ELISA and neutralisation), seroprevalence is estimated as 1% (95% exact binomial confidence intervals 0.7% - 1.3%), again subtantially lower than suggested when using the neutralisation test denominator only. \\\n\n\n\n\n\n::: {.cell .hidden}\n\n```{.r .cell-code}\n#look at why this matters\n\n# total population size\npop_size <- 1000000\n# R0\nr0 <- 4\n# herd immunity threshold\nhit <- 1-1/r0\n# sero diff\nsero_diff <- binom.confint(x = positive_neutralisation,n = 2*positive_elisa,method=\"exact\")$mean - binom.confint(x = positive_neutralisation,n = total_tests,method=\"exact\")$mean \n# CFR\ncfr <- 0.01\n# case hospitalisation ratio\nchr <- 0.2\n```\n:::\n\n\n\n\n\nUsing the incorrect denominator could have important consequences for future planning and control strategies. Consider a population of 1,000,000 people. The basic reproduction number of this novel coronavirus is estimated at around 4, implying a herd immunity threshold (HIT) of 75%. \\\nIf it is (incorrectly) assumed that seroprevalence is 10%, this implies that 660,000 members of the population require immunity before herd immunity is reached. However, it is actually 740,000 members of the population requiring immunity to reach this threshold (an additional 90,000 people) under the correctly specified seroprevalence estimate of 1%. \\\nIf immunity were to be required through vaccination, then an additional 90,000 vaccines would be required. In the absence of a vaccine, e.g. if immunity were to be acquired via natural infection, assuming an overall case hospitalisation ratio (CHR) of 20% and case fatality ratio (CFR) of 1%, this suggests an additional 18,000 hospitalisations and 900 deaths than could be expected under the assumption of a seroprevalence of 10%\nrespectfully. In at least the case of hospitalisation, this may require further preparation at hospital-level and the implementation of surge capacity protocols.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n### team, do we want a plot of something related to this?\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\nWhere parameters are reported or inferred during an active outbreak, we recommend to provide information about the time into the outbreak since the first case was reported and epidemic phase at the time of the analysis, especially when inferring delay distributions (see section 1.5). Further contextual information is also relevant for a nuanced understanding of how parameter estimates may change throughout an outbreak, e.g., due to changes in containment measures, therapeutics and vaccination, or volume of testing. For instance, advancements in the therapeutic approach to critical care patients resulted in a significantly higher delay from onset to death for COVID-19 patients during the summer of 2020 (mean of 24.7 days), compared to the first wave of the pandemic (mean of 19.6 days) (Ward and Johnsen, 2021, PLoS).\n\nContextual information about the disease’s causative agent should also be reported, including pathogen name, and, where applicable, its type, subtype and/or strain. This information is relevant, as the transmissibility, pathogenicity and severity of disease, and their resulting epidemiological parameters often vary across strains of the same pathogen. For instance, the incubation period for Influenza type A is reportedly longer on average than that of Influenza type B, with a median of 1.4 and 0.6 days, respectively (Lessler, 2009).  If the causative agent is unknown to the authors, either due to it being a novel pathogen, or simply because this information is not available, this should be explicitly stated in the publication. Beyond details about the causative agent, authors should also specify the transmission routes that have been considered when estimating parameters. This is particularly crucial for zoonotic and vector-borne diseases, where explicit clarification is needed on whether the estimates account for human-to-human transmission only, or if animal-to-human or vector-to-human transmission is also accounted for. \n\n_Guidance_:\n\n* Provide demographic information about the population and for the sample that was used to estimate epidemiological parameters.\n* Specify whether analyses were stratified by certain groups, e.g., by age, or conducted using data for the whole population.\n* Indicate whether reported parameters were obtained during an ongoing outbreak and, if so, provide information on the epidemic phase and time since outbreak was first declared.\n* Clearly state whether variant(s) of the pathogen of interest is known and, if so, report the name of the variant and how this was determined.\n* Specify which transmission pathways of disease were considered, e.g., human-to-human only, or including animal-to-human transmission.\n\n### Open science and reproducibility to enhance reuse\n\nThe complexities involved in estimating and reporting epidemiological parameters mean that it is unlikely that all methodological aspects and considerations can be documented in the paper or even supplementary material. By sharing data and code it enables reproducibility and auditing of the methods used. Sharing the code used to infer an epidemiological parameter enables others to see which method, as well as any other packages that were used. There are several platforms that easily enable code sharing, most common are GitHub, GitLab and BitBucket. To release the software used and provide a unique identifier (e.g. DOI) services like Zenodo, Figshare and Dyrad, this provides a single referenceable snapshot of the code, removing any issue if the code changes on, for example GitHub. Following these and other good practices for code sharing will help others navigate and review the code (Wilson et al., 2017). Openly sharing code enables others to reproduce the estimates and verify the estimates. They may also be able to assess the quality of the methods with respect to the available data and possible bias-adjustments that may be required when working with real-time outbreak data (citation needed). Sharing the analysis code can also resolve ambiguities in parameter reporting. If the parameterisation of the distribution is unclear from the text (see Section 1) then by checking parameter arguments in the code clarifies their use.\n\nSharing the data is as important as sharing the code. By data we mean the input data (i.e. outbreak case data) and output data (i.e. parameter estimates and fitting metadata). If possible the raw data used to fit a model to estimate an epidemiological parameter should be openly available. By sharing the raw data it enables reproducibility of the analysis used to estimate the epidemiological parameters, but also allows others to apply different models to the data. \n\nOpenly sharing epidemiological data can be restricted by personal identifiable information (PII) and data usage restrictions. There are some methods available to enable reproducibility even when the raw data cannot be shared. Anonymisation, if the personal identifiable information (PII) is not required by the method to infer the epidemiological parameter then this information can be removed, de-identified or anonymised prior to uploading the data (citations needed). Mock or synthetic data can be generated which has the same characteristics as the empirical data. This enables the analysis to be reproduced while removing any risk of identification or leaking personal information. \n\nThe epidemiological parameter output should also be shared in full when possible. Often if the epidemiological parameter are distribution parameters these will be reported in the text. But the estimates correlation matrix, variance-covariance matrix, convergence metrics (e.g. …) should be shared. For Bayesian analyses sharing the posterior distribution is most beneficial for reuse as it allows researchers to calculate whichever summary metric their use case requires (e.g. Highest Posterior Density (HPD) Interval).\n\n\n### Epidemiological parameter use and disjoint analysis pipelines\n\nThe aim of this paper has been to provide a set of reporting guidelines for epidemiological parameter, with the objective to make reusing them in other epidemiological analyses more reliable, with examples showcasing when analysis error can result from erroneous or ambiguous reporting. This argument is premised on the downstream epidemiological analysis being disjoint from the estimation of the epidemiological parameters, in other words the method that uses the parameters to estimate or infer another aspect of an outbreak does not estimate the parameters. An example of this is when an previously estimated generation time, or serial interval as a more commonly available replacement, is used to estimate the real-time reproduction number. If the data is available to jointly estimate the generation time or serial interval with the reproduction number, then this is the statistically optimal approach. However, for a variety of reasons, primarily model complexity of joint models leading to mathematical and computations simplification being required, the disjoint or 2-step analysis procedure is common (ref). Some models to offer joint estimation given sufficient data (ref). There have not been many studies exploring the statistical performance of joint versus disjoint estimation (check this sentence and find ref). There is another aspect to consider, whether a set of epidemiological parameters exists where the features of the data (e.g. sample size, collection procedure) make it more accurate than the available at hand. In this scenario even if a joint estimation framework is available and feasible, it might be better to choose estimated parameters. The contextual information of the data, such as demography, geography, and comorbidities of the sample, should also be considered in such a case as the two groups might not be epidemiologically equivalent.  That is all to say that reporting guidelines are relevant due to the widespread use of disjoint estimation where clear, ambiguous reporting with coverage of key piece of statistical and contextual information are required.\n\n## Conclusion\n\n## References\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}